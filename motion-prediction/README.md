# Motion Prediction
This Repository contains models and datasets for motion prediction.

Models
- Simple Encoder-LSTM-Decoder Network
- Implementation of [VectorNet](https://arxiv.org/pdf/2005.04259v1.pdf) 
- [VectorNet](https://arxiv.org/pdf/2005.04259v1.pdf) with LSTM based agent encoder

Datasets
- [Argoverse](https://www.argoverse.org/av1.html)
- [Argoverse 2](https://www.argoverse.org/av2.html)
- [NuScenes](https://www.nuscenes.org/nuscenes)

## Setup

Create conda enviroment
```
conda env create -f environment.yml
conda activate motion-prediction
```

Install argoverse api
````
pip install numpy==1.19.0 && pip install git+https://github.com/argoai/argoverse-api.git; pip install numpy --upgrade
````

## Data Preparation
### **Argoverse**

Download the Argoverse dataset by following the [Insturctions](https://github.com/argoverse/argoverse-api).

Place files in **_raw\_data_**. Place that folder into the **.data/argoverse** folder.

### **Argoverse 2**

Download the Argoverse 2 dataset by following the [Insturctions](https://github.com/argoverse/av2-api/blob/main/DOWNLOAD.md).

Rename the directory containing **_train_**, **_val_** and **_test_** data to **_raw\_data_**. Place that folder into the **.data/av2** folder.

### **NuScenes**
Download the NuScenes Map expansion v1.3 as well as the trainval metadata from the [NuScenes Website](https://www.nuscenes.org/nuscenes#download).

Move the contents of the map expansion to the map folder of the trainval map folder and rename the folder **_raw\_data_**. Place that folder into the **.data/nuscenes** folder.

## Preprocessing
Preprocess data by running 

```
python preprocess.py --dataset <name of dataset>
```
``preprocess.py`` allowes for the following options to be passed:
- __num_scenarios_train__: number of scenarios processed for training data (default: complete dataset)
- __num_scenarios_val__: number of scenarios processed for val data (default: complete dataset)
- __scenarios_per_file__: number of scenes stored in one processed file (default: 100)
- __left_handed__: generate left handed dataset (this will mirror argoverse data and process the signgapore data for nuscenes)

*Note: Adjust prediction history and horizon by setting **INPUT_LEN** and **PRED_LEN** in ``config.yml``.*

## Train

### Train Model
```
python train.py --dataset <name of dataset> --model <name of model>
```
``train.py`` allowes for the following options to be passed:
- __batch_size__: batch size used for training (default 64)
- __epochs__: number of epochs trained (default see config.yml)
- __lr__: learning rate used for training (default see config.yml)
- __weight_decay__: weight decay used for training (default 0 -> not used)
- __small_dataset__: option to only use fraction of dataset used for training (set in percent)
- __log__: if True saves the tensorboard logs of the learning curves in the _./logs_ folder
- __finetune__: option to pass model saved in _./trained\_models_ and use that to fine tune last layers
- __gpu__: just an option to choose the gpu that is used for trainig
- __num_workers__: number of workers used by the dataloader
- __left_handed__: if true trains on left handed data
- __loss_function__: set to either 'GNLLL' or 'MSE' for training
- __num_predictions__: number of modes K generated by the model

### Train using Optuna for hyperparameter search (**WIP**)
```
python search_hyperparams.py --dataset <name of dataset> --model <name of model>
```
``search_hyperparams.py`` additional parameter:
- __num_trials__: num of trials optuna evlaluates for the hyperparameter search.

_Note:_ 
- *__log__ for tensorboard is not available.*
- *__use\_pretrained__ for training pretrained models is not available.*
## Evaluate

Evaluate trained model in _trained\_models_ by running
```
python evaluate.py --trained_model <file name of trained model> --dataset <name of dataset> --model <name of model architecture>
```
``evaluate.py`` allowes for the following options to be passed:
- __model__: name of model type to evaluate 
- __trained_model__: name of saved model to evaluate 
- __eval_dataset__: chose dataset on which to evaluate on (deflaut 'val')
- __batch_size__: batch size used for evaluation (default 128)
- __small_dataset__: option to only use fraction of dataset used for evaluation (set in percent)
- __eval_left__: evaluate on left handed data
- __eval_by_direction__: evaluates left turns, right turns, straight driving and misc scenes separatly
- __num_workers__: number of workers used by Dataloader
- __loss_function__: set to either 'GNLLL' or 'MSE'
- __save_prediction_horizon__: option to save the safe_prediction horizon (end velocity over last safe prediction timestep)
- __left_handed__: evaluate on left handed data

## Plotting

Plot moving scene by running  (_Note: this is only available for the av2 dataset_)
```
viz.py --moving_scene True --dataset <name of dataset> --scene_idx <index of scene to plot> 
```

Plot vector map of scene by running 
```
viz.py --vector_map True --dataset <name of dataset> --scene_idx <index of scene to plot>
```

Plot 9 random scenes from the dataset
```
viz.py --vector_map_sample True --dataset <name of dataset>
```

Plot vector map and prediction of scene by running 
```
viz.py --prediction <name of trained model> --model <model name> --dataset <name of dataset> --scene_idx <index of scene to plot> 
```

- Chose dataset (train or val) from wich scene should be plotted by passing __dataset_split__ option (default is 'val').
- plot left handed scene by passing __left_handed__ True.

_Note: Scenes have to be preprocessed before plotting_ 
